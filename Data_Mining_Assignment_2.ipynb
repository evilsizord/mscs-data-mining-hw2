{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP6RqM+C16erHoO8w+Eccmc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evilsizord/mscs-data-mining-hw2/blob/main/Data_Mining_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2: Naive Bayes Classifier\n",
        "Daniel Evilsizor \\\n",
        "November 13, 2022"
      ],
      "metadata": {
        "id": "XQM0pRlgfLq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Data from Kaggle.com\n",
        "\n",
        "# NOTE: Requires you to have a Kaggle.com account. From your account you can generate an API key.\n",
        "# It will be provided in kaggle.json. Upload the JSON file to this project BEFORE RUNNING.\n",
        "\n",
        "# src: https://www.kaggle.com/general/74235\n",
        "\n",
        "! pip install -q kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download gaveshjain/ford-sentence-classifiaction-dataset   # yes there is a typo in the actual URL\n",
        "! mkdir sentence-dataset\n",
        "! unzip ford-sentence-classifiaction-dataset.zip -d sentence-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhmeJ5GQfVE3",
        "outputId": "219e33a7-67d0-40f1-968b-33f20f219b63"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Downloading ford-sentence-classifiaction-dataset.zip to /content\n",
            "  0% 0.00/2.92M [00:00<?, ?B/s]\n",
            "100% 2.92M/2.92M [00:00<00:00, 158MB/s]\n",
            "mkdir: cannot create directory ‘sentence-dataset’: File exists\n",
            "Archive:  ford-sentence-classifiaction-dataset.zip\n",
            "  inflating: sentence-dataset/sample_submission.csv  \n",
            "  inflating: sentence-dataset/test_data.csv  \n",
            "  inflating: sentence-dataset/train_data.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load all necessary libraries\n",
        "import os\n",
        "import pandas\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt')  # i guess this is needed for the stemmer\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia4MspXxfWl7",
        "outputId": "1c003620-160b-4e70-b51e-5b052c68a371"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class it up\n",
        "\n",
        "class MyTokenizer:\n",
        "  def __init__(self):\n",
        "    self.stemmer = PorterStemmer()\n",
        "    self.stop_words = set(stopwords.words('english'))\n",
        "\n",
        "  def tokenize(self, doc):\n",
        "    tokens = word_tokenize(doc)\n",
        "    # remove punctuation and stop words\n",
        "    # ref: https://stackoverflow.com/questions/15547409/how-to-get-rid-of-punctuation-using-nltk-tokenizer\n",
        "    # Also, convert to a set so we only get unique words per row (no duplicates)\n",
        "    words = set()\n",
        "    for tok in tokens:\n",
        "      word = self.stemmer.stem(tok)\n",
        "      if not word.lower() in self.stop_words:\n",
        "        if not word in '.,()':\n",
        "          words.add(word)\n",
        "    return words\n",
        "\n",
        "\n",
        "class NaiveBayesClassifier:\n",
        "\n",
        "  def __init__(self, vocab, categories, tokenizer):\n",
        "    self.class_probs = {}     # p(class)\n",
        "    self.categories = categories    # [class1, class2, ..]\n",
        "    self.word_probs = {}      # p(w|class)\n",
        "    self.post_probs = {}      # p(class|w)\n",
        "    self.category_counts = {}\n",
        "    self.vocab = {}\n",
        "    self.tokenize = tokenizer.tokenize\n",
        "    self.use_smoothing = False\n",
        "\n",
        "    for cat in categories:\n",
        "      self.class_probs[cat] = 1\n",
        "      self.category_counts[cat] = 0\n",
        "\n",
        "    for word in vocab:\n",
        "      self.vocab[word] = {'total_frequency': 0}\n",
        "      for cat in categories:\n",
        "        self.vocab[word][cat] = 0\n",
        "\n",
        "  def get_predictors(self, cat, vocab_probs):\n",
        "    predictors = {}\n",
        "    for word in vocab:\n",
        "      # p(class|word) = p(word|class)*p(class)/p(word)\n",
        "      if word in vocab_probs:\n",
        "        predictors[word] = self.word_probs[word + '_' + cat] * self.class_probs[cat] / vocab_probs[word]\n",
        "      else:\n",
        "        predictors[word] = 0\n",
        "    return predictors\n",
        "\n",
        "  # return most likely class for each document\n",
        "  def predict(self, dataset):\n",
        "    # foreach document:\n",
        "    # foreach class, calculate p(class|tokens) = p(tokens|class)*p(class) / p(tokens)\n",
        "    # since p(tokens) is effectively a constant scaling factor when comparing these, we can ignore it\n",
        "    y_hat = []\n",
        "    index = 0\n",
        "    dataset_dict = dataset.copy().to_dict('records')\n",
        "    for row in dataset_dict:\n",
        "      words = self.tokenize(row['New_Sentence'])\n",
        "      category = row['Type']\n",
        "      probs = {}\n",
        "      for cat in categories:\n",
        "        p = self.class_probs[cat]\n",
        "        for w in words:\n",
        "          p2key = w + '_' + cat\n",
        "          p2 = self.word_probs[p2key] if p2key in self.word_probs else 0\n",
        "          p *= p2\n",
        "        probs[cat] = p\n",
        "      \n",
        "      # predicted class is the one with max probability\n",
        "      y_hat.append(max(probs, key=probs.get))\n",
        "      #debug\n",
        "      if index < 10:\n",
        "        print('predict(): probs:', probs)\n",
        "\n",
        "      index += 1\n",
        "      \n",
        "    return y_hat\n",
        "\n",
        "  def count_frequencies(self, dataset):\n",
        "    # use laplace smoothing to ensure there are no zero counts\n",
        "    if self.use_smoothing:\n",
        "      for word in self.vocab:\n",
        "        for cat in self.categories:\n",
        "          dataset.append({'Sentence_id': '__ADDITIVE__', 'New_Sentence': word, 'Type': cat}, ignore_index=True)\n",
        "          # this increases our dataset by ~(24k * 6) ..?\n",
        "\n",
        "    for index, row in dataset.iterrows():\n",
        "      words = self.tokenize(row['New_Sentence'])\n",
        "      category = row['Type']\n",
        "\n",
        "      # increment overall category counts\n",
        "      self.dict_increment(self.category_counts, category)\n",
        "\n",
        "      # count overall word frequency, and frequency per class (label)\n",
        "      for word in words:\n",
        "        self.dict_increment(self.vocab[word], 'total_frequency')\n",
        "        if category not in self.vocab[word]:\n",
        "          self.vocab[word][category] = 0\n",
        "        self.dict_increment(self.vocab[word], category)\n",
        "\n",
        "  # calculate probs from a training dataset\n",
        "  def train(self, dataset):\n",
        "    self.count_frequencies(dataset)\n",
        "\n",
        "    # Calculate\tConditional probability of all words based on category\n",
        "    for cat in self.categories:\n",
        "      self.class_probs[cat] = self.category_counts[cat] / len(dataset)\n",
        "\n",
        "      for word in self.vocab:\n",
        "        #\tP(word|cat)  = # of documents in category containing word / num of all documents in that category\n",
        "        word_cat_freq = self.vocab[word][cat] if cat in self.vocab[word] else 0\n",
        "        self.word_probs[word + '_' + cat] = word_cat_freq / self.category_counts[cat]\n",
        "\n",
        "  # helper function\n",
        "  def dict_increment(self, mydict, mykey):\n",
        "    if not mykey:\n",
        "      return  # if key is False, ignore\n",
        "    if mykey in mydict:\n",
        "      mydict[mykey] += 1\n",
        "    else:\n",
        "      mydict[mykey] = 1\n",
        "\n",
        "  #def _parse(corpus)\n",
        "    #calculate probabilities\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HX5XWxBB0zCe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preview the data\n",
        "input_train = pandas.read_csv('sentence-dataset/train_data.csv')\n",
        "input_test = pandas.read_csv('sentence-dataset/test_data.csv')\n",
        "\n",
        "# throw out the integer indexes before merging\n",
        "input_train = input_train.drop(input_train.columns[[0]], axis=1)\n",
        "input_test = input_test.drop(input_test.columns[[0]], axis=1)\n",
        "\n",
        "all_data = pandas.concat([input_train, input_test])\n",
        "# how many rows?\n",
        "print(len(all_data), 'total rows loaded')\n",
        "\n",
        "# throw out null sentences (see https://stackoverflow.com/a/56708633)\n",
        "all_data['New_Sentence'].replace('', np.nan, inplace=True)\n",
        "all_data.dropna(subset=['New_Sentence'], inplace=True)\n",
        "print(len(all_data), 'rows after removing empty sentences')\n",
        "\n",
        "categories = ['Responsibility', 'Requirement', 'Skill', 'SoftSkill', 'Education', 'Experience']\n",
        "\n",
        "testdata = all_data[ all_data['Type'].isnull() ]\n",
        "traindevdata = all_data[ all_data['Type'].notnull() ]\n",
        "\n",
        "split = int(.5*len(traindevdata))\n",
        "traindata = traindevdata[:split]\n",
        "devdata = traindevdata[(split+1):]\n",
        "\n",
        "print(len(traindata), 'training,', len(devdata), 'dev,', len(testdata), 'test rows loaded')\n",
        "\n",
        "# preview the result\n",
        "all_data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "SfR_MZ2LfYXN",
        "outputId": "d5619991-dee9-4df0-fda1-fd5a0a0b74fd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75144 total rows loaded\n",
            "73750 rows after removing empty sentences\n",
            "29501 training, 29500 dev, 14748 test rows loaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Sentence_id                                       New_Sentence  \\\n",
              "0  GERRES15609  Author and/or Review architecture/design and o...   \n",
              "1  PHERES15784  Should be able to develop custom dynamic shape...   \n",
              "2  GERREQ10457  Experience in working crosslly with a  larger ...   \n",
              "3  GERSKL27235  Previous business experience, including but no...   \n",
              "4  HONSSK18415         Delivering fast and right the first  time.   \n",
              "\n",
              "             Type  \n",
              "0  Responsibility  \n",
              "1  Responsibility  \n",
              "2     Requirement  \n",
              "3           Skill  \n",
              "4       SoftSkill  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23fd7fa3-f089-4770-9125-6bd0c16e56f7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence_id</th>\n",
              "      <th>New_Sentence</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GERRES15609</td>\n",
              "      <td>Author and/or Review architecture/design and o...</td>\n",
              "      <td>Responsibility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PHERES15784</td>\n",
              "      <td>Should be able to develop custom dynamic shape...</td>\n",
              "      <td>Responsibility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GERREQ10457</td>\n",
              "      <td>Experience in working crosslly with a  larger ...</td>\n",
              "      <td>Requirement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GERSKL27235</td>\n",
              "      <td>Previous business experience, including but no...</td>\n",
              "      <td>Skill</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HONSSK18415</td>\n",
              "      <td>Delivering fast and right the first  time.</td>\n",
              "      <td>SoftSkill</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23fd7fa3-f089-4770-9125-6bd0c16e56f7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-23fd7fa3-f089-4770-9125-6bd0c16e56f7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-23fd7fa3-f089-4770-9125-6bd0c16e56f7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set()\n",
        "tokenizer = MyTokenizer()\n",
        "\n",
        "all_data_dict = all_data.to_dict('records')\n",
        "for row in all_data_dict:\n",
        "  tokens = tokenizer.tokenize(row['New_Sentence'])\n",
        "  for tok in tokens:\n",
        "    vocab.add(tok)\n",
        "\n",
        "# preview\n",
        "print('Found', len(vocab), 'words in vocabulary')\n",
        "for id,val in enumerate(vocab):\n",
        "  if id < 25:\n",
        "    print(val + \", \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX_Lls1Wq7Ji",
        "outputId": "24e7d174-b715-4a03-bbb5-caf79d722997"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 24644 words in vocabulary\n",
            "add, \n",
            "payer/provid, \n",
            "-both, \n",
            "cashflow, \n",
            "integration/implement, \n",
            "toronto, \n",
            "alteryx, \n",
            "cpa/cma, \n",
            "processors/soc, \n",
            "boot-load, \n",
            "konzept, \n",
            "london, \n",
            "incid, \n",
            "engine/mechan, \n",
            "tc, \n",
            "optimieren, \n",
            "rdbms/, \n",
            "xae, \n",
            "tant, \n",
            "automation/materi, \n",
            "arbeitsweis, \n",
            "vca/hs, \n",
            "writing/commun, \n",
            "micro-servic, \n",
            "development/upd, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model = NaiveBayesClassifier(vocab, categories, tokenizer)\n",
        "model.train(traindata)"
      ],
      "metadata": {
        "id": "eoILzRWQtDqm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print ('Tokenizer test::')\n",
        "#print(tokenizer.tokenize('Experienced person with funny hat'))"
      ],
      "metadata": {
        "id": "A-bHH6FDAFOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate probability of occurrance of each word\n",
        "vocab_probs = {}\n",
        "for word in vocab:\n",
        "  if (model.vocab[word]['total_frequency'] > 0):    # if freq == 0 that means it did not appear in the training data\n",
        "    vocab_probs[word] = model.vocab[word]['total_frequency'] / len(traindata)\n",
        "\n",
        "# preview: words with highest probability\n",
        "print('Top 5: words with highest probability')\n",
        "for w in sorted(vocab_probs, key=vocab_probs.get, reverse=True)[:8]:\n",
        "  print(w, vocab_probs[w])\n",
        "\n",
        "# preview: words with lowest probability\n",
        "print(\"\\n\",'Bottom 5: words with lowest probability')\n",
        "for w in sorted(vocab_probs, key=vocab_probs.get)[:8]:\n",
        "  print(w, vocab_probs[w])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFAOMotmw7OM",
        "outputId": "bdc93db6-5984-4e2a-9703-934eba2229d9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5: words with highest probability\n",
            "experi 0.2547032303989695\n",
            "year 0.13914782549744076\n",
            "manag 0.10874207653977831\n",
            "work 0.09823395817090946\n",
            "develop 0.08779363411409782\n",
            "skill 0.08606487915663875\n",
            "abil 0.08416663841903664\n",
            "team 0.07318395986576726\n",
            "\n",
            " Bottom 5: words with lowest probability\n",
            "-both 3.38971560286092e-05\n",
            "tc 3.38971560286092e-05\n",
            "xae 3.38971560286092e-05\n",
            "pb/pba 3.38971560286092e-05\n",
            "hrg 3.38971560286092e-05\n",
            "req354000 3.38971560286092e-05\n",
            "current/futur 3.38971560286092e-05\n",
            "amonthlybasi 3.38971560286092e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preview Conditional Probabilities (computed during training)\n",
        "\n",
        "print('Top 5 Conditional probability')\n",
        "for w in sorted(model.word_probs, key=model.word_probs.get, reverse=True)[:5]:\n",
        "  print(w, model.word_probs[w])\n",
        "\n",
        "print()\n",
        "print('Bottom 5 Conditional probability')\n",
        "for w in sorted(model.word_probs, key=model.word_probs.get)[:5]:\n",
        "  print(w, model.word_probs[w])\n",
        "\n",
        "# Preview class probabilities\n",
        "print()\n",
        "print('Class probabilities')\n",
        "for cat in categories:\n",
        "  print(cat, model.class_probs[cat])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJihGMTy09Je",
        "outputId": "74d8e2a0-1d49-4010-8152-80100a27699c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Conditional probability\n",
            "year_Experience 0.8757982823166703\n",
            "experi_Experience 0.8465095793878\n",
            "degre_Education 0.5115967885816235\n",
            "engin_Education 0.34834968777876896\n",
            "experi_Skill 0.32862606649014414\n",
            "\n",
            "Bottom 5 Conditional probability\n",
            "payer/provid_Responsibility 0.0\n",
            "-both_Responsibility 0.0\n",
            "cashflow_Responsibility 0.0\n",
            "integration/implement_Responsibility 0.0\n",
            "toronto_Responsibility 0.0\n",
            "\n",
            "Class probabilities\n",
            "Responsibility 0.258567506186231\n",
            "Requirement 0.23633097183146334\n",
            "Skill 0.11521643334124267\n",
            "SoftSkill 0.1599606792990068\n",
            "Education 0.07599742381614183\n",
            "Experience 0.15392698552591438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try predicting labels for dev data\n",
        "Y_hat = model.predict(devdata)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtIkSVK9-iLk",
        "outputId": "a0f41063-79f5-4469-aa29-acf236b3f023"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predict(): probs: {'Responsibility': 1.1816508956975302e-07, 'Requirement': 1.422776346892155e-08, 'Skill': 1.1177913805473846e-09, 'SoftSkill': 3.725592190982312e-10, 'Education': 3.7068765868595185e-09, 'Experience': 4.518509105151025e-09}\n",
            "predict(): probs: {'Responsibility': 0.0, 'Requirement': 4.6166745660219734e-21, 'Skill': 0.0, 'SoftSkill': 0.0, 'Education': 5.394091927120312e-19, 'Experience': 8.347573644211712e-19}\n",
            "predict(): probs: {'Responsibility': 5.05870020249462e-35, 'Requirement': 0.0, 'Skill': 0.0, 'SoftSkill': 0.0, 'Education': 0.0, 'Experience': 0.0}\n",
            "predict(): probs: {'Responsibility': 1.3633227100284912e-24, 'Requirement': 0.0, 'Skill': 0.0, 'SoftSkill': 0.0, 'Education': 0.0, 'Experience': 0.0}\n",
            "predict(): probs: {'Responsibility': 0.0, 'Requirement': 0.0, 'Skill': 0.0, 'SoftSkill': 0.0, 'Education': 0.0, 'Experience': 0.0}\n",
            "predict(): probs: {'Responsibility': 2.4885169606739843e-07, 'Requirement': 1.7065263577225802e-06, 'Skill': 7.230196563913406e-06, 'SoftSkill': 1.4366245403097775e-07, 'Education': 0.0, 'Experience': 5.240212184999704e-06}\n",
            "predict(): probs: {'Responsibility': 0.258567506186231, 'Requirement': 0.23633097183146334, 'Skill': 0.11521643334124267, 'SoftSkill': 0.1599606792990068, 'Education': 0.07599742381614183, 'Experience': 0.15392698552591438}\n",
            "predict(): probs: {'Responsibility': 0.0, 'Requirement': 0.0, 'Skill': 0.0, 'SoftSkill': 0.0, 'Education': 0.0, 'Experience': 0.0}\n",
            "predict(): probs: {'Responsibility': 0.0, 'Requirement': 5.5963014082653505e-15, 'Skill': 2.183572360209223e-18, 'SoftSkill': 6.622192554308342e-13, 'Education': 0.0, 'Experience': 5.451094702007473e-19}\n",
            "predict(): probs: {'Responsibility': 1.4410400228431798e-07, 'Requirement': 2.530662622985135e-07, 'Skill': 2.7363749554586716e-09, 'SoftSkill': 1.7781564431589922e-06, 'Education': 7.309079930273148e-11, 'Experience': 6.57985962088218e-10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Responsibility predictions:', len([y for y in Y_hat if y == 'Responsibility']))\n",
        "print('SoftSkill predictions:', len([y for y in Y_hat if y == 'SoftSkill']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9MQIr9DHEZL",
        "outputId": "f4c267f6-d064-4aa2-a55e-28f24a90f230"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Responsibility predictions: 14045\n",
            "SoftSkill predictions: 3754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "def calculate_accuracy(Y, Y_hat):\n",
        "  num_correct = 0\n",
        "  index=0\n",
        "  if len(Y) != len(Y_hat):\n",
        "    print('data invalid length', len(Y), ':', len(Y_hat))\n",
        "    return False\n",
        "  for row in Y:\n",
        "    y_hat = Y_hat[index]\n",
        "    y = row['Type']\n",
        "    num_correct += 1 if y_hat == y else 0\n",
        "    index += 1\n",
        "  return num_correct / len(Y)\n",
        "\n",
        "Y = devdata.to_dict('records')\n",
        "accuracy = calculate_accuracy(Y, Y_hat)\n",
        "\n",
        "print('Accuracy for Dev data:', accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se5s7pAhBT0z",
        "outputId": "96702e49-4c6f-4a73-a155-43e85c81c608"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Dev data: 0.580406779661017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the result with smoothing\n",
        "#model2 = NaiveBayesClassifier(vocab, categories, tokenizer)\n",
        "#model2.use_smoothing = True\n",
        "#model2.train(traindata)\n",
        "\n",
        "#Y_hat = model2.predict(devdata)\n",
        "#accuracy = calculate_accuracy(Y, Y_hat)\n",
        "\n",
        "#print('Accuracy with smoothing:', accuracy)\n"
      ],
      "metadata": {
        "id": "0aJODZdgLNlS"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Derive Top 10 words that predicts each class\n",
        "for cat in categories:\n",
        "  print('Top 10 for category', cat)\n",
        "  t2 = model.get_predictors(cat, vocab_probs)\n",
        "  for w in sorted(t2, key=t2.get, reverse=True)[:10]:\n",
        "    print(w, t2[w])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q12b4gkgMf1Y",
        "outputId": "0f7c3156-342a-4abe-a779-50152e12d9f6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 for category Responsibility\n",
            "xae 1.0\n",
            "lubric 1.0\n",
            "pb/pba 1.0\n",
            "hrg 1.0\n",
            "current/futur 1.0\n",
            "amonthlybasi 1.0\n",
            "conducta 1.0\n",
            "serez 1.0\n",
            "cooption 1.0\n",
            "hochintergrativ 1.0\n",
            "Top 10 for category Requirement\n",
            "-both 1.0\n",
            "req354000 1.0\n",
            "erfordern 1.0\n",
            "rlevant 1.0\n",
            "req355943 1.0\n",
            "cca 1.0\n",
            "haveshould 1.0\n",
            "freehand 1.0\n",
            "studiengangs/vergleichbar 1.0\n",
            "diagnostiqu 1.0\n",
            "Top 10 for category Skill\n",
            "orm 1.0\n",
            "weblog 1.0\n",
            "lookup 1.0\n",
            "corptax 1.0\n",
            "pwa 1.0\n",
            "mockito 1.0\n",
            "wsdl 1.0\n",
            "appdynam 1.0\n",
            "jwt 1.0\n",
            "simulink 1.0\n",
            "Top 10 for category SoftSkill\n",
            "arbeitsweis 1.0\n",
            "lexcel 1.0\n",
            "hoher 1.0\n",
            "numeraci 1.0\n",
            "dinteragir 1.0\n",
            "stabl 1.0\n",
            "bco 1.0\n",
            "client-interact 1.0\n",
            "souci 1.0\n",
            "sprach 1.0\n",
            "Top 10 for category Education\n",
            "cpa/cma 1.0\n",
            "tc 1.0\n",
            "btech/b 1.0\n",
            "aeroespac 1.0\n",
            "biomedizintechnik 1.0\n",
            "copa 1.0\n",
            "3.0 1.0\n",
            "sociaux 1.0\n",
            "science-rel 1.0\n",
            "electromecca 1.0\n",
            "Top 10 for category Experience\n",
            "universitxe9 1.0000000000000002\n",
            "15+ 1.0000000000000002\n",
            "dau 1.0000000000000002\n",
            "5-6 1.0000000000000002\n",
            "value3+ 1.0\n",
            "6-10 1.0\n",
            "r8 1.0\n",
            "logistics/suppli 1.0\n",
            "white/gray/black 1.0\n",
            "powergen/util 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "CSV reader example code:\\\n",
        "https://realpython.com/python-csv/\n",
        "\n",
        "https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
        "\n",
        "https://www.geeksforgeeks.org/python-stemming-words-with-nltk/?ref=lbp\n",
        "\n",
        "https://stackoverflow.com/questions/29314033/drop-rows-containing-empty-cells-from-a-pandas-dataframe\n",
        "\n",
        "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value\n",
        "\n",
        "https://towardsdatascience.com/heres-the-most-efficient-way-to-iterate-through-your-pandas-dataframe-4dad88ac92ee"
      ],
      "metadata": {
        "id": "mt01xYnnkhzr"
      }
    }
  ]
}